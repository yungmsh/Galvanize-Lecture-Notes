`w2.d2`
## Estimation

iid is an imperative assumption in Maximum Likelihood Estimation (MLE)
We can multiply the conditional probabilities because of the iid condition.
But turns out we can ADD the log probabilities instead (easier).

Kernel Density Estimation (KDE) is used for smoothing the data.
The kernel function takes in x and h (bandwidth parameter).
The idea is to give a smoother version of a histogram.
An example is that it's basically a summation of many Gaussian distributions.

## Sampling

Simple random: best in theory but hard in practice
Stratified sampling: try to get the groups to mimic the actual population sizes (eg under 25/over 25)
Cluster sampling
Systematic sampling: choose a random start point, then use a systematic method in which you sample (e.g. every 10 houses, interview 1). But it's important to consider underlying patterns in the data. (e.g. what if there are 10 houses per block, and corner-block real estate is highest)

Central Limit Theorem: the pillar which modern statistics rests upon
The mean of a sufficiently large number of iid RVs are approximately normally distributed (regardless of the underlying distribution)
Conditions:
- Sample size (min 30)
- iid
- Only works well distributions with well-defined mean and variance

In the context of CLT, variance is actually smaller! (div by n)

As n goes up, the confidence interval shrinks (even without adjusting the alpha component)

If sample size is small (<30), use the t-distribution with degrees of freedom = n-1
T-distribution has fatter tails

## Bootstrapping
Sampling with replacement.
Sample has n size.
Each bootstrap sample is the same size as the original sample (n).
Repeat B times.
This is useful for getting information about the distribution of other parameters (other than the mean)

If you're trying to estimate the mean, use CLT.
If you're trying to estimate anything else, use Bootstrapping.

----------
`w2.d3`
## Hypothesis Testing

Null hypothesis (H0) is typically the status quo (or the 'belief')

Significance level
alpha: probability of rejecting the null when it is true
alpha is basically the Type 1 Error

### Errors
Type 1 Error:
When the null is true, and we reject it anyway
Type 2 Error (Power):
When the null is false, but we accept it anyway (fail to reject!)
You can reduce Type 2 Error by collecting more data (narrows the normal distribution)

p value: probability of observing THE DATA we observed, or more extreme, given that the null hypothesis is true

Use a t-distribution if n<30 and sigma unknown (if unsure, just use t anyway)
Degrees of freedom is equiv to n

SciPy T-test:
scs.ttest_1samp(sample, mu)

Bonferroni Correction: a way of correcting for multi-variate testing.
Use alpha/n (where n is the number of variables you're changing)


### Chi-Squared Test:
- To estimate if two RV are independent
- To estimate how closely an observed distribution matches an expected distribution (the goodness-of-fit test)

df = (row-1)(cols-1)

example for hypothesis test:
H0: Political party is independent of gender
H1: Political party is dependent on gender

----------
`w2.d5`
## Bayesian vs Frequentist

Benefits of Bayesian framework:
- Flexibility
- Ease of communication
- Can continuously monitor/change variables in the test

Conjugate Priors:
If the prior is beta distributed and the likelihood is Bernoulli/binomial, then the posterior will also be beta distributed.

Method for Bayesian A/B Testing:
- Sample repeatedly from each distribution
- Count how often site A has a high rate than site B


Boring A/B testing: exploration.... then exploitation
But that's costly.
So how do we exploit while minimizing the costs of exploring?

Regret is the success metric.
We want to minimize regret
R = sum of (p_opt - p_i)
where p is a payout

The basic idea of any of these algorithms is having a methodology that forces you to explore while optimizing on the best payout option

### ALGORITHMS

#### Epsilon-greedy:
Set an epsilon (0.1 or less)
    if prob <= epsilon:
      Explore
    else:
      Exploit
This is not a zero-regret strategy, because epsilon-percent of the time you are exploring.

#### UCB1:
Upper Confidence Bound 1
Calculate a prob for each bandit
Use the bandit with the max value for a given equation
pA + sqrt(2logN / nA)
where pA is payout, N is no of times the whole game has been played, n is no of times bandit A has been played

#### softmax
Choose a bandit in proportion to its estimated value
tau can be flexible as you test


Questions:
Bayesian bandit: only works for equal payouts?
